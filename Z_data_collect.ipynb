{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing location 1...\n",
      "Processing location 2...\n",
      "Processing location 3...\n",
      "Processing location 4...\n",
      "Processing location 5...\n",
      "Processing location 6...\n",
      "Processing location 7...\n",
      "Processing location 8...\n",
      "Processing location 9...\n",
      "Processing location 10...\n",
      "Processing location 11...\n",
      "Processing location 12...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"2025-02-13T00:00\" doesn't match format \"%Y-%m-%dT%H:%M:%SZ\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m     save_data(results)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 102\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 96\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(process_location, idx, loc): idx \u001b[38;5;28;01mfor\u001b[39;00m idx, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(locations)}\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[1;32m---> 96\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m     98\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(result)\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[7], line 66\u001b[0m, in \u001b[0;36mprocess_location\u001b[1;34m(index, location)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weather_data:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hour, time_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;66;03m# Parse the timestamp correctly\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m         timestamp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mSZ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m: lat,\n\u001b[0;32m     69\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m: lon,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msunshine_duration\u001b[39m\u001b[38;5;124m'\u001b[39m: weather_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msunshine_duration\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m])[hour]\n\u001b[0;32m     80\u001b[0m         })\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1101\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[0;32m   1103\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"2025-02-13T00:00\" doesn't match format \"%Y-%m-%dT%H:%M:%SZ\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Output directory and file paths\n",
    "output_dir = './weather_data/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'final_open_meteo_hourly_weather_data.xlsx')\n",
    "progress_file = os.path.join(output_dir, 'progress.txt')\n",
    "\n",
    "# Open-Meteo API base URL for hourly data\n",
    "base_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "# List of 10 places with latitude, longitude, and time ranges\n",
    "locations = [\n",
    "    {\"latitude\": 27.0031, \"longitude\": 95.3556, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Pakke Tiger Reserve, Arunachal Pradesh\n",
    "    {\"latitude\": 26.7890, \"longitude\": 93.2923, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Kaziranga National Park, Assam\n",
    "    {\"latitude\": 25.6667, \"longitude\": 91.5000, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Nongkhyllem Wildlife Sanctuary, Meghalaya\n",
    "    {\"latitude\": 26.8500, \"longitude\": 93.7333, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Nameri National Park, Assam\n",
    "    {\"latitude\": 27.2110, \"longitude\": 93.5150, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Namdapha National Park, Arunachal Pradesh\n",
    "    {\"latitude\": 26.4673, \"longitude\": 92.7500, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Manas National Park, Assam\n",
    "    {\"latitude\": 27.5447, \"longitude\": 91.6206, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Eaglenest Wildlife Sanctuary, Arunachal Pradesh\n",
    "    {\"latitude\": 24.1394, \"longitude\": 92.4492, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Dampa Tiger Reserve, Mizoram\n",
    "    {\"latitude\": 27.1000, \"longitude\": 92.3670, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Dibang Valley, Arunachal Pradesh\n",
    "    {\"latitude\": 26.6673, \"longitude\": 88.3926, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Singalila National Park, West Bengal\n",
    "    {\"latitude\": 10.3666, \"longitude\": 76.6413, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Silent Valley National Park, Kerala\n",
    "    {\"latitude\": 11.1442, \"longitude\": 75.8764, \"start\": \"2025-01-01T00:00:00Z\", \"end\": \"2025-01-02T00:00:00Z\"},  # Wayanad Wildlife Sanctuary, Kerala\n",
    "]\n",
    "\n",
    "\n",
    "# Function to fetch hourly data from Open-Meteo API with retries\n",
    "def fetch_open_meteo_hourly_data(lat, lon, start_datetime, end_datetime, retries=3, delay=2):\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start\": start_datetime,\n",
    "        \"end\": end_datetime,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\", \"windspeed_10m\", \"relative_humidity_2m\", \"precipitation\",\n",
    "            \"dewpoint_2m\", \"cloudcover\", \"surface_pressure\", \"shortwave_radiation\",\n",
    "            \"sunshine_duration\"\n",
    "        ],\n",
    "        \"timezone\": \"UTC\"\n",
    "    }\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(base_url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            data = response.json().get(\"hourly\", {})\n",
    "            if data:\n",
    "                return data\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            time.sleep(delay)\n",
    "    return None\n",
    "\n",
    "# Process a single location\n",
    "def process_location(index, location):\n",
    "    print(f\"Processing location {index + 1}...\")\n",
    "    lat, lon, start_datetime, end_datetime = location['latitude'], location['longitude'], location['start'], location['end']\n",
    "    weather_data = fetch_open_meteo_hourly_data(lat, lon, start_datetime, end_datetime)\n",
    "    results = []\n",
    "    if weather_data:\n",
    "        for hour, time_value in enumerate(weather_data['time']):\n",
    "            results.append({\n",
    "                'latitude': lat,\n",
    "                'longitude': lon,\n",
    "                'timestamp': pd.to_datetime(time_value),\n",
    "                'temperature': weather_data.get('temperature_2m', [None])[hour],\n",
    "                'windspeed': weather_data.get('windspeed_10m', [None])[hour],\n",
    "                'humidity': weather_data.get('relative_humidity_2m', [None])[hour],\n",
    "                'precipitation': weather_data.get('precipitation', [None])[hour],\n",
    "                'dewpoint': weather_data.get('dewpoint_2m', [None])[hour],\n",
    "                'cloud_cover': weather_data.get('cloudcover', [None])[hour],\n",
    "                'pressure': weather_data.get('surface_pressure', [None])[hour],\n",
    "                'solar_radiation': weather_data.get('shortwave_radiation', [None])[hour],\n",
    "                'sunshine_duration': weather_data.get('sunshine_duration', [None])[hour]\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Save processed data\n",
    "def save_data(results):\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_excel(output_file, index=False)\n",
    "        print(f\"Weather data saved to {output_file}.\")\n",
    "\n",
    "# Process all locations\n",
    "def main():\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(process_location, idx, loc): idx for idx, loc in enumerate(locations)}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                results.extend(result)\n",
    "    save_data(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ee\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Initialize Google Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='ee-71762205062')\n",
    "\n",
    "# Function to get elevation using Google Earth Engine SRTM dataset\n",
    "def get_elevation_ee(lat, lon):\n",
    "    try:\n",
    "        point = ee.Geometry.Point(lon, lat)\n",
    "        elevation = ee.Image('USGS/SRTMGL1_003').select('elevation')\n",
    "        result = elevation.reduceRegion(\n",
    "            reducer=ee.Reducer.first(),\n",
    "            geometry=point,\n",
    "            scale=30  # 30m resolution\n",
    "        ).get('elevation')\n",
    "        return result.getInfo() if result else None\n",
    "    except Exception as e:\n",
    "        print(f\"EE Elevation Error: lat {lat}, lon {lon}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get NDVI using updated MODIS dataset\n",
    "def get_modis_ndvi(lat, lon, start_date, end_date):\n",
    "    try:\n",
    "        point = ee.Geometry.Point(lon, lat)\n",
    "        collection = ee.ImageCollection('MODIS/061/MOD13Q1') \\\n",
    "            .filterBounds(point) \\\n",
    "            .filterDate(start_date, end_date)\n",
    "        image = collection.first()\n",
    "        if not image:\n",
    "            return None\n",
    "        ndvi = image.select('NDVI').clip(point)\n",
    "        result = ndvi.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=point,\n",
    "            scale=250  # MODIS spatial resolution is 250m\n",
    "        ).get('NDVI')\n",
    "        return result.getInfo() if result else None\n",
    "    except Exception as e:\n",
    "        print(f\"NDVI Error: lat {lat}, lon {lon}, {start_date} - {end_date}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process a single location\n",
    "def process_location(location):\n",
    "    lat, lon = location['rounded_lat'], location['rounded_lon']\n",
    "    elevation = get_elevation_ee(lat, lon)\n",
    "    location_results = []\n",
    "    for year in [2014]:\n",
    "        for month in range(1, 13):\n",
    "            start_date = f\"{year}-{month:02d}-01\"\n",
    "            end_date = pd.to_datetime(start_date) + pd.offsets.MonthEnd(1)\n",
    "            ndvi = get_modis_ndvi(lat, lon, start_date, end_date.strftime('%Y-%m-%d'))\n",
    "            location_results.append({\n",
    "                'latitude': lat,\n",
    "                'longitude': lon,\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'ndvi': ndvi,\n",
    "                'elevation': elevation\n",
    "            })\n",
    "            print(ndvi,month,year,lat,lon)\n",
    "    return location_results\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel('weather_data_2014_06_15.xlsx')\n",
    "\n",
    "    # Round latitude and longitude\n",
    "    df['rounded_lat'] = df['latitude'].round(2)\n",
    "    df['rounded_lon'] = df['longitude'].round(2)\n",
    "\n",
    "    # Get unique lat/lon combinations\n",
    "    unique_locations = df[['rounded_lat', 'rounded_lon']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use ThreadPoolExecutor for concurrent processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(process_location, location): location for _, location in unique_locations.iterrows()}\n",
    "\n",
    "        # Collect results as they complete\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                location_results = future.result()\n",
    "                results.extend(location_results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing location: {e}\")\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save results to Excel\n",
    "    results_df.to_excel('ndvi_elevation_2015_20161.xlsx', index=False)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Processing complete! Total time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample df1\n",
    "df1 = pd.DataFrame({\n",
    "    'latitude': [26.789, 26.789, 26.789],\n",
    "    'longitude': [93.2923, 93.2923, 93.2923],\n",
    "    'timestamp': ['2025-01-01 00:00:00', '2025-01-01 01:00:00', '2025-01-01 02:00:00'],\n",
    "    'temperature': [14.6, 15.0, 16.2],\n",
    "    'windspeed': [0.8, 1.5, 1.6],\n",
    "    'humidity': [96, 94, 92],\n",
    "    'precipitation': [0, 0, 0],\n",
    "    'dewpoint': [13.9, 14.0, 14.9],\n",
    "    'cloud_cover': [37, 26, 66],\n",
    "    'pressure': [1002.1, 1003.4, 1004.5],\n",
    "    'solar_radiation': [0, 8, 123],\n",
    "    'sunshine_duration': [0, 0, 3600]\n",
    "})\n",
    "\n",
    "# Sample df2\n",
    "df2 = pd.DataFrame({\n",
    "    'latitude': [27.1, 27.1],\n",
    "    'longitude': [92.37, 92.37],\n",
    "    'year': [2025, 2025],\n",
    "    'month': [1, 2],\n",
    "    'ndvi': [8546, None],\n",
    "    'elevation': [1912, 1912]\n",
    "})\n",
    "\n",
    "# Convert the 'timestamp' in df1 to datetime and extract year and month\n",
    "df1['timestamp'] = pd.to_datetime(df1['timestamp'])\n",
    "df1['year'] = df1['timestamp'].dt.year\n",
    "df1['month'] = df1['timestamp'].dt.month\n",
    "\n",
    "# Merge df1 and df2 on latitude, longitude, year, and month\n",
    "df_merged = pd.merge(df1, df2, on=['latitude', 'longitude', 'year', 'month'], how='left')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df_merged)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
